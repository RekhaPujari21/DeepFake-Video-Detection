{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e3c5f53-9b38-4e4b-a06e-14bd14b686ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\users\\hp\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.73.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in d:\\users\\hp\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in d:\\users\\hp\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in d:\\users\\hp\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\users\\hp\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a671f-fcf9-4de6-8ec3-289bcf45a4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-contrib-python\n",
    "# !pip install imageio\n",
    "\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import imageio\n",
    "import cv2\n",
    "import os\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f36870-79a1-4e33-9131-8997dc6b692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = r'C:\\Users\\HP\\Downloads\\DeepFake\\dataset'\n",
    "TRAIN_SAMPLE_FOLDER =  r'C:\\Users\\HP\\Downloads\\DeepFake\\dataset\\train_sample_videos'\n",
    "TEST_FOLDER =r'C:\\Users\\HP\\Downloads\\DeepFake\\dataset\\test_videos'\n",
    "\n",
    "print(f\"train samples: {len(os.listdir(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER)))}\")\n",
    "print(f\"test samples: {len(os.listdir(os.path.join(DATA_FOLDER, TEST_FOLDER)))}\")  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d27f9f1-9c50-4446-9fbf-61b3071017a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_metadata = pd.read_json(r'C:\\Users\\HP\\Downloads\\DeepFake\\dataset\\train_sample_videos\\metadata.json').T\n",
    "train_sample_metadata.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741cd041-673a-43d3-a712-5655b54ad9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_metadata.groupby('label')['label'].count().plot(figsize=(5,5),kind='bar',title='The Label in the Training Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02e2b8e-ff12-471f-b8fb-ec6a94c10efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610ec50-df2c-4972-ba3e-acee9d41146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of video file names\n",
    "f_videos = list(train_sample_metadata[train_sample_metadata.label == 'FAKE'].index)\n",
    "r_videos = list(train_sample_metadata[train_sample_metadata.label == 'REAL'].index)\n",
    "\n",
    "# Function to play video in notebook\n",
    "def play_video(video_file, subset='train_sample_videos'):\n",
    "    video_path = os.path.join(DATA_FOLDER, subset, video_file)\n",
    "    video_url = open(video_path, 'rb').read()\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(video_url).decode()\n",
    "    return HTML(f\"\"\"<video width=500 controls><source src=\"{data_url}\" type=\"video/mp4\"></video>\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b639b9-b59f-404a-85f5-3957f344ff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "max_seq_length = 20\n",
    "num_features = 2048\n",
    "\n",
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x - min_dim) // 2\n",
    "    start_y = (y - min_dim) // 2\n",
    "    return frame[start_y:start_y+min_dim, start_x:start_x+min_dim]\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(img_size, img_size)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]  # BGR to RGB\n",
    "            frames.append(frame)\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12556fa6-5a80-4727-84c8-9d0138efc43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_feature_extractor():\n",
    "    base_model = keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\", include_top=False, pooling=\"avg\", input_shape=(img_size, img_size, 3)\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((img_size, img_size, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "    outputs = base_model(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "feature_extractor = pretrain_feature_extractor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff14fc20-2070-4a9c-a0dd-48de3fac6f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    video_paths = list(df.index)\n",
    "    labels = np.array(df[\"label\"] == 'FAKE').astype(int)\n",
    "\n",
    "    frame_masks = np.zeros((num_samples, max_seq_length), dtype=\"bool\")\n",
    "    frame_features = np.zeros((num_samples, max_seq_length, num_features), dtype=\"float32\")\n",
    "\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        frames = load_video(os.path.join(DATA_FOLDER, root_dir, path))\n",
    "        frames = frames[None, ...]\n",
    "        temp_mask = np.zeros((1, max_seq_length), dtype=\"bool\")\n",
    "        temp_features = np.zeros((1, max_seq_length, num_features), dtype=\"float32\")\n",
    "\n",
    "        length = min(max_seq_length, frames.shape[1])\n",
    "        for j in range(length):\n",
    "            temp_features[0, j, :] = feature_extractor.predict(frames[:, j, :])[0]\n",
    "        temp_mask[0, :length] = 1\n",
    "\n",
    "        frame_features[idx] = temp_features.squeeze()\n",
    "        frame_masks[idx] = temp_mask.squeeze()\n",
    "\n",
    "    return (frame_features, frame_masks), labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4289604a-d27c-46ee-b762-b21935b7e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set, Test_set = train_test_split(\n",
    "    train_sample_metadata, test_size=0.1, random_state=42, stratify=train_sample_metadata['label']\n",
    ")\n",
    "print(\"Train shape:\", Train_set.shape)\n",
    "print(\"Test shape:\", Test_set.shape)\n",
    "\n",
    "train_data, train_labels = prepare_all_videos(Train_set, 'train_sample_videos')\n",
    "test_data, test_labels = prepare_all_videos(Test_set, 'train_sample_videos')\n",
    "\n",
    "print(f\"Train frame features shape: {train_data[0].shape}\")\n",
    "print(f\"Train frame masks shape: {train_data[1].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f69c7-8d79-4403-9d27-8e21a2b0714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_features_input = keras.Input((max_seq_length, num_features))\n",
    "mask_input = keras.Input((max_seq_length,), dtype=\"bool\")\n",
    "\n",
    "x = keras.layers.GRU(16, return_sequences=True)(frame_features_input, mask=mask_input)\n",
    "x = keras.layers.GRU(8)(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "output = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model([frame_features_input, mask_input], output)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    './best_model.weights.h5', save_weights_only=True, save_best_only=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [train_data[0], train_data[1]],\n",
    "    train_labels,\n",
    "    validation_data=([test_data[0], test_data[1]], test_labels),\n",
    "    callbacks=[checkpoint],\n",
    "    epochs=70,\n",
    "    batch_size=8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36c18dd-0e9a-420c-8523-c9487d815954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_single_video(frames):\n",
    "    frames = frames[None, ...]\n",
    "    frame_mask = np.zeros((1, max_seq_length), dtype=\"bool\")\n",
    "    frame_features = np.zeros((1, max_seq_length, num_features), dtype=\"float32\")\n",
    "\n",
    "    video_length = frames.shape[1]\n",
    "    length = min(max_seq_length, video_length)\n",
    "    for j in range(length):\n",
    "        frame_features[0, j, :] = feature_extractor.predict(frames[:, j, :])[0]\n",
    "    frame_mask[0, :length] = 1\n",
    "\n",
    "    return frame_features, frame_mask\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    frames = load_video(os.path.join(TEST_FOLDER, path))\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "    return model.predict([frame_features, frame_mask])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5914048-441f-4465-aaf6-0a710f72a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load random or fixed video\n",
    "test_videos = pd.DataFrame(os.listdir(TEST_FOLDER), columns=[\"video\"])\n",
    "test_video = np.random.choice(test_videos[\"video\"])\n",
    "print(f\"Test video: {test_video}\")\n",
    "\n",
    "# Predict and display result\n",
    "prediction = sequence_prediction(test_video)\n",
    "if prediction >= 0.5:\n",
    "    print(\"Predicted class: FAKE\")\n",
    "else:\n",
    "    print(\"Predicted class: REAL\")\n",
    "\n",
    "# Show video in notebook\n",
    "play_video(test_video, 'test_videos')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
